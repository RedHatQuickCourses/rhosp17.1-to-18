:_mod-docs-content-type: PROCEDURE
[id="adopting-compute-services-to-the-data-plane_{context}"]

= Adopting Compute services to the {rhos_acro} data plane

[role="_abstract"]
Adopt your Compute (nova) services to the {rhos_long} data plane.

.Prerequisites

* You have stopped the remaining control plane nodes, repositories, and packages on the {compute_service_first_ref} hosts. For more information, see xref:stopping-infrastructure-management-and-compute-services_{context}[Stopping infrastructure management and Compute services].
* You have configured the Ceph back end for the `NovaLibvirt` service. For more information, see xref:configuring-a-ceph-backend_migrating-databases[Configuring a Ceph back end].
* You have configured IP Address Management (IPAM). On the *utility host*, execute the following command:
+
[source,bash,role=execute]
----
cd ~/labrepo/files
oc apply -f osp-ng-dataplane-netconfig.yaml
----
+

* You have defined the shell variables to run the script that runs the upgrade:
+
[source,bash,role=execute]
----
CEPH_FSID=$(oc get secret ceph-conf-files -o json | jq -r '.data."ceph.conf"' | base64 -d | grep fsid | sed -e 's/fsid = //')

alias openstack="oc exec -t openstackclient -- openstack"

DEFAULT_CELL_NAME="cell1"
RENAMED_CELLS="cell1"

declare -A COMPUTES_CELL1
export COMPUTES_CELL1=(
  ["overcloud-novacompute-0.localdomain"]="172.25.249.19"
  ["overcloud-novacompute-1.localdomain"]="172.25.249.22"
)

declare -A COMPUTES_API_CELL1
export COMPUTES_API_CELL1=(
  ["overcloud-novacompute-0.localdomain"]="192.168.122.100"
  ["overcloud-novacompute-1.localdomain"]="172.25.249.22"
)

NODESETS=""
for CELL in $(echo $RENAMED_CELLS); do
  ref="COMPUTES_$(echo ${CELL}|tr '[:lower:]' '[:upper:]')"
  eval names=\${!${ref}[@]}
  [ -z "$names" ] && continue
  NODESETS="'openstack-${CELL}', $NODESETS"
done
NODESETS="[${NODESETS%,*}]"
----

.Procedure

* Get the libvirt secret password:
+
[source,bash,role=execute]
----
LIBVIRT_PASSWORD=$(cat ~/overcloud-passwords.yaml | grep ' LibvirtTLSPassword:' | awk -F ': ' '{ print $2; }')
LIBVIRT_PASSWORD_BASE64=$(echo -n "$LIBVIRT_PASSWORD" | base64)
----
+

. Create the libvirt secret:
+
[source,yaml,role=execute]
----
oc apply -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: libvirt-secret
  namespace: openstack
type: Opaque
data:
  LibvirtPassword: ${LIBVIRT_PASSWORD_BASE64}
EOF
----

. Create an SSH authentication secret for the data plane nodes:
+
[source,bash,role=execute]
[subs=+quotes]
----
oc create secret generic dataplane-ansible-ssh-private-key-secret --save-config --dry-run=client --from-file=authorized_keys=/home/lab/.ssh/id_rsa_tripleo.pub --from-file=ssh-privatekey=/home/lab/.ssh/id_rsa_tripleo --from-file=ssh-publickey=/home/lab/.ssh/id_rsa_tripleo.pub -n openstack -o yaml | oc apply -f-
----

. Generate an ssh key-pair `nova-migration-ssh-key` secret:
+
[source,bash,role=execute]
----
cd "$(mktemp -d)"
ssh-keygen -f ./id -t ecdsa-sha2-nistp521 -N ''
oc get secret nova-migration-ssh-key || oc create secret generic nova-migration-ssh-key \
  --from-file=ssh-privatekey=id \
  --from-file=ssh-publickey=id.pub \
  --type kubernetes.io/ssh-auth
rm -f id*
cd -
----

. Create a configuration map to use for all cells to configure a local storage back end for libvirt:
+
[source,bash,role=execute]
----
oc apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: nova-cells-global-config
data: 
  99-nova-compute-cells-workarounds.conf: |
    [workarounds]
    disable_compute_service_check_for_ffu=true
EOF
----
+
[NOTE]
If you adopt a live cloud, you might be required to carry over additional configurations for the default `nova` data plane services that are stored in the cell1 default `nova-extra-config` configuration map. Do not delete or overwrite the existing configuration in the `cell1` default `nova-extra-config` configuration map that is assigned to `nova`. Overwriting the configuration can break the data place services that rely on specific contents of the `nova-extra-config` configuration map.

. Configure a {Ceph} back end for libvirt:
+
[source,bash,role=execute]
----
oc apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: nova-cells-global-config
data:
  99-nova-compute-cells-workarounds.conf: |
    [workarounds]
    disable_compute_service_check_for_ffu=true
  03-ceph-nova.conf: |
    [libvirt]
    images_type=rbd
    images_rbd_pool=vms
    images_rbd_ceph_conf=/etc/ceph/ceph.conf
    images_rbd_glance_store_name=default_backend
    images_rbd_glance_copy_poll_interval=15
    images_rbd_glance_copy_timeout=600
    rbd_user=openstack
    rbd_secret_uuid=$CEPH_FSID
EOF
----
+
[NOTE]
For {Ceph} environments with multi-cell configurations, you must name configuration maps and {rhos_prev_long} data plane services similar to the following examples: `nova-custom-ceph-cellX` and `nova-compute-extraconfig-cellX`.

. Create the data plane services for {compute_service} cells to enable pre-upgrade workarounds, and to configure the Compute services for your chosen storage back end:
+
[source,bash,role=execute]
----
for CELL in $(echo $RENAMED_CELLS); do
 oc apply -f - <<EOF
---
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneService
metadata:
  name: nova-$CELL
spec:
  dataSources:
    - secretRef:
        name: nova-$CELL-compute-config
    - secretRef:
        name: nova-migration-ssh-key
    - configMapRef:
        name: nova-cells-global-config
  playbook: osp.edpm.nova
  caCerts: combined-ca-bundle
  edpmServiceType: nova
  containerImageFields:
  - NovaComputeImage
  - EdpmIscsidImage
EOF
  done
----

[NOTE]
====
When creating your data plane services for {compute_service} cells, review the following considerations:

* In this example, the same `nova-migration-ssh-key` key is shared across cells. However, you should use different keys for different cells.
* For simple configuration overrides, you do not need a custom data plane service. However, to reconfigure the cell, `cell1`,
the safest option is to create a custom service and a dedicated configuration map for it.
* The cell, `cell1`, is already managed with the default `OpenStackDataPlaneService` CR called `nova` and its `nova-extra-config` configuration map. Do not change the default data plane service `nova` definition. The changes are lost when the {rhos_acro} operator is updated with OLM.
* When a cell spans multiple node sets, give the custom `OpenStackDataPlaneService` resources a name that relates to the node set, for example, `nova-cell1-nfv` and `nova-cell1-enterprise`. The auto-generated configuration maps are then named `nova-cell1-nfv-extra-config` and `nova-cell1-enterprise-extra-config`.
* Different configurations for nodes in multiple node sets of the same cell are also supported, but are not covered in this guide.
====

. Create a secret for the subscription manager:
+
[source,bash,role=execute]
----
oc create secret generic subscription-manager \
--from-literal rhc_auth='{"login": {"username": "<subscription_manager_username>", "password": "<subscription_manager_password>"}}'
----
+
* Replace `<subscription_manager_username>` with the applicable username.
* Replace `<subscription_manager_password>` with the applicable password.

. Create a secret for the Red Hat registry:
+
[source,bash,role=execute]
----
oc create secret generic redhat-registry \
--from-literal edpm_container_registry_logins='{"registry.redhat.io": {"<registry_username>": "<registry_password>"}}'
----
+
* Replace `<registry_username>` with the applicable username.
* Replace `<registry_password>` with the applicable password.

+

[NOTE]
You do not need to reference the `subscription-manager` secret in the `dataSources` field of the `OpenStackDataPlaneService` CR.
The secret is already passed in with a node-specific `OpenStackDataPlaneNodeSet` CR in the `ansibleVarsFrom` property in the `nodeTemplate` field.


. Create the `OpenStackDataPlaneNodeSet` CRs corresponding to `overcloud-novacompute-0` and `overcloud-novacompute-1`:
+
[source,bash,role=execute,subs=attributes]
----
oc apply -f osp-ng-dataplane-node-set-deploy-adoption-compute.yaml
----

. Run the pre-adoption validation:

.. Create the validation service:
+
[source,bash,role=execute]
----
oc apply -f - <<EOF
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneService
metadata:
  name: pre-adoption-validation
spec:
  playbook: osp.edpm.pre_adoption_validation
EOF
----

.. Create a `OpenStackDataPlaneDeployment` CR that runs only the validation:
+
[source,bash,role=execute]
----
oc apply -f - <<EOF
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneDeployment
metadata:
  name: openstack-pre-adoption
spec:
  nodeSets:
  - compute0-1-set
  servicesOverride:
  - pre-adoption-validation
EOF
----
+

.. When the validation is finished, confirm that the status of the Ansible EE pods is `Completed`:
+
[source,bash,role=execute]
----
watch oc get pod -l app=openstackansibleee
----
+
----
oc logs -l app=openstackansibleee -f --max-log-requests 20
----

.. Wait for the deployment to reach the `Ready` status:
+
[source,bash,role=execute]
----
oc wait --for condition=Ready openstackdataplanedeployment/openstack-pre-adoption --timeout=10m
----
+
[IMPORTANT]
====
If any openstack-pre-adoption validations fail, you must reference the Ansible logs to determine which ones were unsuccessful, and then try the following troubleshooting options:

* If the hostname validation failed, check that the hostname of the data plane
node is correctly listed in the `OpenStackDataPlaneNodeSet` CR.

* If the kernel argument check failed, ensure that the kernel argument configuration in the `edpm_kernel_args` and `edpm_kernel_hugepages` variables in the `OpenStackDataPlaneNodeSet` CR is the same as the kernel argument configuration that you used in the {rhos_prev_long} ({OpenStackShort}) {rhos_prev_ver} node.

* If the tuned profile check failed, ensure that the
`edpm_tuned_profile` variable in the `OpenStackDataPlaneNodeSet` CR is configured
to use the same profile as the one set on the {OpenStackShort} {rhos_prev_ver} node.
====

. Remove the remaining {OpenStackPreviousInstaller} services:

.. Create an `OpenStackDataPlaneService` CR to clean up the data plane services you are adopting:
+
[source,bash,role=execute]
----
oc apply -f - <<EOF
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneService
metadata:
  name: tripleo-cleanup
spec:
  playbook: osp.edpm.tripleo_cleanup
EOF
----

.. Create the `OpenStackDataPlaneDeployment` CR to run the clean-up:
+
[source,bash,role=execute]
----
oc apply -f - <<EOF
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneDeployment
metadata:
  name: tripleo-cleanup
spec:
  nodeSets:
  - compute0-1-set
  servicesOverride:
  - tripleo-cleanup
EOF
----

. When the clean-up is finished, deploy the `OpenStackDataPlaneDeployment` CR that performs the dataplane adoption:
+
[source,bash,role=execute]
----
oc apply -f - <<EOF
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneDeployment
metadata:
  name: dataplane-adoption
spec:
  nodeSets:
  - compute0-1-set
  
EOF
----
+
[NOTE]
If you have other node sets to deploy, such as Networker nodes, you can
add them in the `nodeSets` list in this step, or create separate `OpenStackDataPlaneDeployment` CRs later. You cannot add new node sets to an `OpenStackDataPlaneDeployment` CR after deployment.

.Verification

. Confirm that all the Ansible EE pods reach a `Completed` status:
+
[source,bash,role=execute]
----
watch oc get pod -l app=openstackansibleee
----
+
[source,bash,role=execute]
----
oc logs -l app=openstackansibleee -f --max-log-requests 20
----

. Wait for the data plane node sets to reach the `Ready` status:
+
[source,bash,role=execute]
----
oc wait --for condition=Ready osdpns/compute0-1-set --timeout=30m
----

.Next steps

* You must perform a fast-forward upgrade on your Compute services. For more information, see xref:performing-a-fast-forward-upgrade-on-compute-services_{context}[Performing a fast-forward upgrade on Compute services].
